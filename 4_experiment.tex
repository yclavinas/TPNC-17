\section{Experiment Design}

In this section we describe how the experiments were conducted.


\subsection{GA-BBOB}\label{sec:proposed:ga-bbob}

In the work, we implemented the GA-BBOB, which is a real-valued Genetic Algorithm to explore the search space of the 24 noise free N dimension BBOB benchmark functions~\cite{hansen2010real}.

\subsubsection*{Genome Representation and Evolutionary Tools.}
Each individual is represented as real valued array, where each element is one input to a N dimension noise free benchmark BBOB function. Therefore, each individual of the GA-BBOB has size of N real value elements. Each individual's values is set to the be into the interval [-5, 5], once those function are limited by these values. It uses the Uniform crossover, elitism and Gaussian mutation are used as evolutionary operators. The relevant parameters were set as Elite Size = 1, Crossover chance = 0.9, Mutation Chance = 0.1. For the Gaussian mutation, these parameters were chosen: mean = 0, Standard deviation = 1, and independent probability for each attribute to be mutated = 0.1.


\subsubsection*{Fitness Function.}
The fitness function considered are the N dimensions noise free benchmark BBOB function. For more information, please refer to the work of Hansen et al.~\cite{hansen2010real}.
Consequently, the GA-BBOB has 24 different fitness functions. 


\subsubsection*{Implementation Details.}
Chuang et al.~\cite{chuang2012black}, proposed a Genetic Algorithm specific to run on the noise free BBOB benchmark functions. Some good practices presented in this work were incorporated to the GA-BBOB. These practice are the concept of ``restart strategy'' and the concept of ``alleviate stagnation''.

The restart strategy concept is defined by Chuang et al. as: ``For each restart, the initial population  is uniformly and randomly sampled within the search space. Whenever the restart condition is met, the algorithm will be reinitialized without using any information about the last test run. This process is iterated until the stopping criteria are met, i.e., maximum number of function evaluations has been reached, or the function value is less than the target precision.''

The restart condition used in the GA-BBOB is value of the standard deviation of the current population. If it is smaller that $10^{-12}$, then the restart condition is triggered. Therefore, when it is contemplated the algorithm population is reinitialized randomly, as it is in the first initialization. 

In the GA-BBOB, we consider information about the last run, by utilizing the Elitism strategy on the best individual prior to the restart. The maximum number of function evaluations chosen is ($4 * 10^5$) and the target precision chosen is ($10^{-8}$), values compatible with the ones in the previous work.

\subsubsection*{Genetic Algorithms and Benchmarks Functions.}

IN 2009, Nicolau~\cite{nicolau2009application} proposed the first Genetic Algorithm on the BBOB-2009 noiseless testbed. It was a simple binary Genetic Algorithm and its results showed good results on separable functions, but poor performance is achieved on the other functions.

In 2012, Chuang et al.~\cite{chuang2012black} presented the ``DBRCGA'', a real coded Genetic Algorithm that uses relative fitness information to direct the crossover toward a direction that significantly improves the objective fitness. The DBRCGA was tested on the BBOB-2012 noiseless testbed. Their results showed that the DBRCGA performs with difficulty in getting a solution with the desired accuracy for high conditioning and multimodal functions within the specified maximum number of evaluations, the DBRCGA presents good performance in separable function and functions with low or moderate conditioning.

In 2013, Holtschulte et al.~\cite{holtschulte2013benchmarking} evaluated two Genetic Algorithm on the BBOB-2013 noiseless testbed, but none had results competitive with the best 2009 optimization algorithm. Their results highlight the importance of carefully chosen genetic operators.

Sawyerr et al found simliar results to the one achieved by Chuang et al. on their works in 2013~\cite{sawyerr2013benchmarking} and in 2015~\cite{sawyerr2015benchmarking}. In 2013, they proposed the ``PRCGA'', or projection-based real-coded genetic algorithm. It incorporates exploratory search mecanism based on vector projection. In 2015, they have studied a hybrid application of the Genetic Algorithm (GA) with the \textit{uniform random direction} search, named ``RCGAu''. BOth the PRCGA and the RCGAu were tested on the BBOB-2013 noiseless testbed. They stated that both of them had difficulties to achieve solutions with the desired accuracy for high conditioning and multimodal functions, though they were able to solve the benchmark functions.  Sawyerr et al concluded that the RCGAu has excelled in solving the $f_1$, $f_2$, $f_3$, $f_7$ and $f_{21}$, tough for the other functions it achieved avarage results. They also state that real value GA do not efficiently solve highly conditioned problems and studies have currently been carried out to find out why~\cite{sawyerr2015benchmarking}.




\label{sec:experiment}

\subsection{Experiments}
We made two experiments aiming to verify the impact of fluctuating the tournament size value. In the first experiment, we analysed the relation between the tournament size and the performance on the BBOB benchmark functions. The second experiment, we analyse the impact of fluctuating the values of the tournament size \textit{during} the execution.

We used ANOVA to test whether any of the combinations shows a
significant deviation in terms of tournament size values, represented as the
quality of the result given functions and dimensions. In each of these tests, we set
$\alpha = 0.05$.

\subsubsection*{Fixed tournament size}

To analyze the impact of the tournament size into the GA-BBOB in therms of quality of result, the following experiments were performed. First we analyse different values for the tournament size applied to the BBOB benchmark functions with 10, 20 and 40 dimensions. The tournament sizes were select, arbitarily, from 2 to 25. For each combination of BBOB benchmark functions, dimensions, and tournament size we performed 40 repetions.


\subsubsection*{Fluctuating tournament size}

To analyze the impact of fluctuating the tournament size \textit{during} the execution into the GA-BBOB in therms of quality of result, the following experiments were performed. We start with the tournament size equal to 2, as many of the work cited on section~\ref{sec:background:tournament_size}. Then when half of the evaluations are completed, the tournament size is changed to another value, chosen from 2 to 25. These values were applied to the BBOB benchmark functions with 10, 20 and 40 dimensions For each combination of BBOB benchmark functions, dimensions, and fluctuating tournament size we performed 40 repetions.


